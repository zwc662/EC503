{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"../santander-customer-transaction-prediction/train-200K samples with labels-10%targets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20098"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_data.target)\n",
    "# 20098 of them are label 1, approximately 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29094</th>\n",
       "      <td>train_29094</td>\n",
       "      <td>1</td>\n",
       "      <td>16.1572</td>\n",
       "      <td>7.9968</td>\n",
       "      <td>5.7262</td>\n",
       "      <td>5.3983</td>\n",
       "      <td>11.8431</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>6.9020</td>\n",
       "      <td>17.5647</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.5898</td>\n",
       "      <td>7.8978</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>4.7748</td>\n",
       "      <td>14.3033</td>\n",
       "      <td>-1.9249</td>\n",
       "      <td>1.8920</td>\n",
       "      <td>8.0455</td>\n",
       "      <td>10.4091</td>\n",
       "      <td>9.1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81454</th>\n",
       "      <td>train_81454</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7612</td>\n",
       "      <td>0.2018</td>\n",
       "      <td>10.5336</td>\n",
       "      <td>6.7798</td>\n",
       "      <td>10.3364</td>\n",
       "      <td>-6.2342</td>\n",
       "      <td>6.3289</td>\n",
       "      <td>15.1656</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4946</td>\n",
       "      <td>10.6336</td>\n",
       "      <td>1.4025</td>\n",
       "      <td>3.8907</td>\n",
       "      <td>20.3836</td>\n",
       "      <td>-1.7819</td>\n",
       "      <td>-0.4499</td>\n",
       "      <td>8.7548</td>\n",
       "      <td>14.3842</td>\n",
       "      <td>-2.7612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126757</th>\n",
       "      <td>train_126757</td>\n",
       "      <td>1</td>\n",
       "      <td>12.7405</td>\n",
       "      <td>-4.8914</td>\n",
       "      <td>13.2755</td>\n",
       "      <td>9.0710</td>\n",
       "      <td>8.8562</td>\n",
       "      <td>-3.0776</td>\n",
       "      <td>6.1806</td>\n",
       "      <td>13.4231</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5175</td>\n",
       "      <td>9.4812</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>-0.6367</td>\n",
       "      <td>21.1369</td>\n",
       "      <td>-0.6886</td>\n",
       "      <td>6.5173</td>\n",
       "      <td>8.6781</td>\n",
       "      <td>18.8952</td>\n",
       "      <td>-27.9383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81436</th>\n",
       "      <td>train_81436</td>\n",
       "      <td>1</td>\n",
       "      <td>7.6062</td>\n",
       "      <td>-5.7881</td>\n",
       "      <td>8.5228</td>\n",
       "      <td>5.7798</td>\n",
       "      <td>11.5769</td>\n",
       "      <td>-6.6377</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>13.8390</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8450</td>\n",
       "      <td>3.7620</td>\n",
       "      <td>-0.1900</td>\n",
       "      <td>-6.1016</td>\n",
       "      <td>18.8138</td>\n",
       "      <td>-1.8027</td>\n",
       "      <td>9.6588</td>\n",
       "      <td>7.7694</td>\n",
       "      <td>15.3515</td>\n",
       "      <td>14.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81438</th>\n",
       "      <td>train_81438</td>\n",
       "      <td>1</td>\n",
       "      <td>13.2652</td>\n",
       "      <td>1.5462</td>\n",
       "      <td>16.2339</td>\n",
       "      <td>9.3391</td>\n",
       "      <td>8.6914</td>\n",
       "      <td>-4.1305</td>\n",
       "      <td>7.8517</td>\n",
       "      <td>23.9764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>9.6809</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>3.5669</td>\n",
       "      <td>18.9545</td>\n",
       "      <td>-1.1964</td>\n",
       "      <td>-6.0121</td>\n",
       "      <td>9.1534</td>\n",
       "      <td>13.9499</td>\n",
       "      <td>4.8177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "29094    train_29094       1  16.1572  7.9968   5.7262  5.3983  11.8431   \n",
       "81454    train_81454       1   8.7612  0.2018  10.5336  6.7798  10.3364   \n",
       "126757  train_126757       1  12.7405 -4.8914  13.2755  9.0710   8.8562   \n",
       "81436    train_81436       1   7.6062 -5.7881   8.5228  5.7798  11.5769   \n",
       "81438    train_81438       1  13.2652  1.5462  16.2339  9.3391   8.6914   \n",
       "\n",
       "         var_5   var_6    var_7   ...     var_190  var_191  var_192  var_193  \\\n",
       "29094   0.8831  6.9020  17.5647   ...     -1.5898   7.8978   0.6694   4.7748   \n",
       "81454  -6.2342  6.3289  15.1656   ...      7.4946  10.6336   1.4025   3.8907   \n",
       "126757 -3.0776  6.1806  13.4231   ...      6.5175   9.4812   0.4055  -0.6367   \n",
       "81436  -6.6377  6.1840  13.8390   ...      2.8450   3.7620  -0.1900  -6.1016   \n",
       "81438  -4.1305  7.8517  23.9764   ...      0.5300   9.6809   0.7063   3.5669   \n",
       "\n",
       "        var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "29094   14.3033  -1.9249   1.8920   8.0455  10.4091   9.1993  \n",
       "81454   20.3836  -1.7819  -0.4499   8.7548  14.3842  -2.7612  \n",
       "126757  21.1369  -0.6886   6.5173   8.6781  18.8952 -27.9383  \n",
       "81436   18.8138  -1.8027   9.6588   7.7694  15.3515  14.4020  \n",
       "81438   18.9545  -1.1964  -6.0121   9.1534  13.9499   4.8177  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_all_data = all_data.sort_values(by='target',ascending=False)\n",
    "sorted_all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20098"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Xy55 = sorted_all_data[0:40196] #The amount of label_1 vs the amount of label_0 is 1:1\n",
    "Xy55 = sorted_all_data[0:40196]\n",
    "sum(Xy55.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = First_Ten_K_data.drop([\\'target\\'], axis=1) \\n#if set inplace = True, then the original DataFrame will also execute the drop;\\n#inplace = False by default\\ny_train = First_Ten_K_data[[\"target\"]] #if only one [], then the return type is Series, [[]] will return a DF\\n\\nX_test = Second_Ten_K_data.drop([\\'target\\'], axis=1)\\ny_test = Second_Ten_K_data[[\\'target\\']]\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train = First_Ten_K_data.drop(['target'], axis=1) \n",
    "#if set inplace = True, then the original DataFrame will also execute the drop;\n",
    "#inplace = False by default\n",
    "y_train = First_Ten_K_data[[\"target\"]] #if only one [], then the return type is Series, [[]] will return a DF\n",
    "\n",
    "X_test = Second_Ten_K_data.drop(['target'], axis=1)\n",
    "y_test = Second_Ten_K_data[['target']]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy55.drop(['ID_code','target'], axis=1) \n",
    "#if we don't drop the 'ID_code', when fit SVM, it will show like \"could not convert string to float: 'train_3783'\"\n",
    "y = Xy55[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29094</th>\n",
       "      <td>16.1572</td>\n",
       "      <td>7.9968</td>\n",
       "      <td>5.7262</td>\n",
       "      <td>5.3983</td>\n",
       "      <td>11.8431</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>6.9020</td>\n",
       "      <td>17.5647</td>\n",
       "      <td>5.0969</td>\n",
       "      <td>7.5070</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.5898</td>\n",
       "      <td>7.8978</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>4.7748</td>\n",
       "      <td>14.3033</td>\n",
       "      <td>-1.9249</td>\n",
       "      <td>1.8920</td>\n",
       "      <td>8.0455</td>\n",
       "      <td>10.4091</td>\n",
       "      <td>9.1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81454</th>\n",
       "      <td>8.7612</td>\n",
       "      <td>0.2018</td>\n",
       "      <td>10.5336</td>\n",
       "      <td>6.7798</td>\n",
       "      <td>10.3364</td>\n",
       "      <td>-6.2342</td>\n",
       "      <td>6.3289</td>\n",
       "      <td>15.1656</td>\n",
       "      <td>3.5367</td>\n",
       "      <td>6.7148</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4946</td>\n",
       "      <td>10.6336</td>\n",
       "      <td>1.4025</td>\n",
       "      <td>3.8907</td>\n",
       "      <td>20.3836</td>\n",
       "      <td>-1.7819</td>\n",
       "      <td>-0.4499</td>\n",
       "      <td>8.7548</td>\n",
       "      <td>14.3842</td>\n",
       "      <td>-2.7612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126757</th>\n",
       "      <td>12.7405</td>\n",
       "      <td>-4.8914</td>\n",
       "      <td>13.2755</td>\n",
       "      <td>9.0710</td>\n",
       "      <td>8.8562</td>\n",
       "      <td>-3.0776</td>\n",
       "      <td>6.1806</td>\n",
       "      <td>13.4231</td>\n",
       "      <td>1.8213</td>\n",
       "      <td>7.7023</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5175</td>\n",
       "      <td>9.4812</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>-0.6367</td>\n",
       "      <td>21.1369</td>\n",
       "      <td>-0.6886</td>\n",
       "      <td>6.5173</td>\n",
       "      <td>8.6781</td>\n",
       "      <td>18.8952</td>\n",
       "      <td>-27.9383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81436</th>\n",
       "      <td>7.6062</td>\n",
       "      <td>-5.7881</td>\n",
       "      <td>8.5228</td>\n",
       "      <td>5.7798</td>\n",
       "      <td>11.5769</td>\n",
       "      <td>-6.6377</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>13.8390</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>6.5611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8450</td>\n",
       "      <td>3.7620</td>\n",
       "      <td>-0.1900</td>\n",
       "      <td>-6.1016</td>\n",
       "      <td>18.8138</td>\n",
       "      <td>-1.8027</td>\n",
       "      <td>9.6588</td>\n",
       "      <td>7.7694</td>\n",
       "      <td>15.3515</td>\n",
       "      <td>14.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81438</th>\n",
       "      <td>13.2652</td>\n",
       "      <td>1.5462</td>\n",
       "      <td>16.2339</td>\n",
       "      <td>9.3391</td>\n",
       "      <td>8.6914</td>\n",
       "      <td>-4.1305</td>\n",
       "      <td>7.8517</td>\n",
       "      <td>23.9764</td>\n",
       "      <td>-3.9925</td>\n",
       "      <td>7.2727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>9.6809</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>3.5669</td>\n",
       "      <td>18.9545</td>\n",
       "      <td>-1.1964</td>\n",
       "      <td>-6.0121</td>\n",
       "      <td>9.1534</td>\n",
       "      <td>13.9499</td>\n",
       "      <td>4.8177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "29094   16.1572  7.9968   5.7262  5.3983  11.8431  0.8831  6.9020  17.5647   \n",
       "81454    8.7612  0.2018  10.5336  6.7798  10.3364 -6.2342  6.3289  15.1656   \n",
       "126757  12.7405 -4.8914  13.2755  9.0710   8.8562 -3.0776  6.1806  13.4231   \n",
       "81436    7.6062 -5.7881   8.5228  5.7798  11.5769 -6.6377  6.1840  13.8390   \n",
       "81438   13.2652  1.5462  16.2339  9.3391   8.6914 -4.1305  7.8517  23.9764   \n",
       "\n",
       "         var_8   var_9   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "29094   5.0969  7.5070   ...     -1.5898   7.8978   0.6694   4.7748  14.3033   \n",
       "81454   3.5367  6.7148   ...      7.4946  10.6336   1.4025   3.8907  20.3836   \n",
       "126757  1.8213  7.7023   ...      6.5175   9.4812   0.4055  -0.6367  21.1369   \n",
       "81436   0.8570  6.5611   ...      2.8450   3.7620  -0.1900  -6.1016  18.8138   \n",
       "81438  -3.9925  7.2727   ...      0.5300   9.6809   0.7063   3.5669  18.9545   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "29094   -1.9249   1.8920   8.0455  10.4091   9.1993  \n",
       "81454   -1.7819  -0.4499   8.7548  14.3842  -2.7612  \n",
       "126757  -0.6886   6.5173   8.6781  18.8952 -27.9383  \n",
       "81436   -1.8027   9.6588   7.7694  15.3515  14.4020  \n",
       "81438   -1.1964  -6.0121   9.1534  13.9499   4.8177  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823414</td>\n",
       "      <td>0.955217</td>\n",
       "      <td>0.198430</td>\n",
       "      <td>0.402073</td>\n",
       "      <td>0.604414</td>\n",
       "      <td>0.670090</td>\n",
       "      <td>0.767056</td>\n",
       "      <td>0.529790</td>\n",
       "      <td>0.767590</td>\n",
       "      <td>0.506796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405305</td>\n",
       "      <td>0.542890</td>\n",
       "      <td>0.347162</td>\n",
       "      <td>0.567106</td>\n",
       "      <td>0.257994</td>\n",
       "      <td>0.339710</td>\n",
       "      <td>0.509595</td>\n",
       "      <td>0.336090</td>\n",
       "      <td>0.199519</td>\n",
       "      <td>0.732786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435627</td>\n",
       "      <td>0.617285</td>\n",
       "      <td>0.505042</td>\n",
       "      <td>0.512628</td>\n",
       "      <td>0.451794</td>\n",
       "      <td>0.518996</td>\n",
       "      <td>0.670540</td>\n",
       "      <td>0.410733</td>\n",
       "      <td>0.687550</td>\n",
       "      <td>0.386757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699779</td>\n",
       "      <td>0.687921</td>\n",
       "      <td>0.409052</td>\n",
       "      <td>0.536827</td>\n",
       "      <td>0.605255</td>\n",
       "      <td>0.355413</td>\n",
       "      <td>0.434595</td>\n",
       "      <td>0.459831</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.550391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644269</td>\n",
       "      <td>0.396483</td>\n",
       "      <td>0.679918</td>\n",
       "      <td>0.695983</td>\n",
       "      <td>0.301858</td>\n",
       "      <td>0.586007</td>\n",
       "      <td>0.645565</td>\n",
       "      <td>0.324260</td>\n",
       "      <td>0.599548</td>\n",
       "      <td>0.536389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668106</td>\n",
       "      <td>0.626830</td>\n",
       "      <td>0.324883</td>\n",
       "      <td>0.381766</td>\n",
       "      <td>0.648278</td>\n",
       "      <td>0.475468</td>\n",
       "      <td>0.657720</td>\n",
       "      <td>0.446451</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>0.166444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375068</td>\n",
       "      <td>0.357609</td>\n",
       "      <td>0.376795</td>\n",
       "      <td>0.432602</td>\n",
       "      <td>0.577450</td>\n",
       "      <td>0.510430</td>\n",
       "      <td>0.646138</td>\n",
       "      <td>0.344899</td>\n",
       "      <td>0.550078</td>\n",
       "      <td>0.363467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549061</td>\n",
       "      <td>0.323641</td>\n",
       "      <td>0.274609</td>\n",
       "      <td>0.194598</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>0.353129</td>\n",
       "      <td>0.758327</td>\n",
       "      <td>0.287922</td>\n",
       "      <td>0.455623</td>\n",
       "      <td>0.812127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671781</td>\n",
       "      <td>0.675568</td>\n",
       "      <td>0.868602</td>\n",
       "      <td>0.717438</td>\n",
       "      <td>0.285164</td>\n",
       "      <td>0.563655</td>\n",
       "      <td>0.926994</td>\n",
       "      <td>0.847976</td>\n",
       "      <td>0.301292</td>\n",
       "      <td>0.471293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.637416</td>\n",
       "      <td>0.350277</td>\n",
       "      <td>0.525737</td>\n",
       "      <td>0.523636</td>\n",
       "      <td>0.419707</td>\n",
       "      <td>0.256466</td>\n",
       "      <td>0.529370</td>\n",
       "      <td>0.382995</td>\n",
       "      <td>0.665968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.823414  0.955217  0.198430  0.402073  0.604414  0.670090  0.767056   \n",
       "1  0.435627  0.617285  0.505042  0.512628  0.451794  0.518996  0.670540   \n",
       "2  0.644269  0.396483  0.679918  0.695983  0.301858  0.586007  0.645565   \n",
       "3  0.375068  0.357609  0.376795  0.432602  0.577450  0.510430  0.646138   \n",
       "4  0.671781  0.675568  0.868602  0.717438  0.285164  0.563655  0.926994   \n",
       "\n",
       "        7         8         9      ...          190       191       192  \\\n",
       "0  0.529790  0.767590  0.506796    ...     0.405305  0.542890  0.347162   \n",
       "1  0.410733  0.687550  0.386757    ...     0.699779  0.687921  0.409052   \n",
       "2  0.324260  0.599548  0.536389    ...     0.668106  0.626830  0.324883   \n",
       "3  0.344899  0.550078  0.363467    ...     0.549061  0.323641  0.274609   \n",
       "4  0.847976  0.301292  0.471293    ...     0.474019  0.637416  0.350277   \n",
       "\n",
       "        193       194       195       196       197       198       199  \n",
       "0  0.567106  0.257994  0.339710  0.509595  0.336090  0.199519  0.732786  \n",
       "1  0.536827  0.605255  0.355413  0.434595  0.459831  0.405500  0.550391  \n",
       "2  0.381766  0.648278  0.475468  0.657720  0.446451  0.639250  0.166444  \n",
       "3  0.194598  0.515600  0.353129  0.758327  0.287922  0.455623  0.812127  \n",
       "4  0.525737  0.523636  0.419707  0.256466  0.529370  0.382995  0.665968  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize the data:\n",
    "from sklearn import preprocessing\n",
    "import pandas\n",
    "\n",
    "x = X.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "X = pandas.DataFrame(x_scaled)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_data[[\"target\"]]\n",
    "X = all_data.drop(['ID_code','target'], axis=1)\n",
    "X_train2,X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3998"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test.target) #in this testing set, we totally have 4123 data whose label is \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16100"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> \n",
      " <class 'pandas.core.frame.DataFrame'> \n",
      " <class 'pandas.core.frame.DataFrame'> \n",
      " <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),'\\n', type(y_train),'\\n', type(X_test),'\\n', type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 36s, sys: 716 ms, total: 3min 37s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#svc = svm.SVC(kernel='poly') #default degree = 3\n",
    "svc = svm.SVC() \n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('SVM Accuracy on test data is:', svc.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4022"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data ROC AUC:0.500\n",
      "Original Data Accuracy:0.101\n",
      "ROC AUC:0.779\n",
      "Accuracy:0.779\n",
      "CPU times: user 3min 31s, sys: 648 ms, total: 3min 32s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score,accuracy_score\n",
    "y_predict2=svc.predict(X_test2)\n",
    "print ('Original Data ROC AUC:%.3f'%roc_auc_score(y_true=y_test2,y_score=y_predict2))\n",
    "print ('Original Data Accuracy:%.3f'%accuracy_score(y_true=y_test2,y_pred=y_predict2))\n",
    "\n",
    "y_predict=svc.predict(X_test)\n",
    "print ('ROC AUC:%.3f'%roc_auc_score(y_true=y_test,y_score=y_predict))\n",
    "print ('Accuracy:%.3f'%accuracy_score(y_true=y_test,y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "3978\n"
     ]
    }
   ],
   "source": [
    "print(str(sum(y_predict2))+ '\\n' + str(sum(y_predict))) #We can see that the classifier predict all the Original \n",
    "#test data as label_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's try PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "CPU times: user 15.4 s, sys: 2.2 s, total: 17.6 s\n",
      "Wall time: 8.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "pca=PCA(n_components=50)     #加载PCA算法，设置降维后主成分数目为50\n",
    "pca_X=pca.fit_transform(X)#对样本进行降维\n",
    "print(str(pca_X.shape) + '\\n' + str(type(pca_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453439</td>\n",
       "      <td>0.259504</td>\n",
       "      <td>0.460966</td>\n",
       "      <td>0.546587</td>\n",
       "      <td>0.528921</td>\n",
       "      <td>0.377153</td>\n",
       "      <td>0.524471</td>\n",
       "      <td>0.308691</td>\n",
       "      <td>0.629793</td>\n",
       "      <td>0.514874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346300</td>\n",
       "      <td>0.540284</td>\n",
       "      <td>0.403092</td>\n",
       "      <td>0.475057</td>\n",
       "      <td>0.391564</td>\n",
       "      <td>0.359514</td>\n",
       "      <td>0.533142</td>\n",
       "      <td>0.527310</td>\n",
       "      <td>0.418510</td>\n",
       "      <td>0.720473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718723</td>\n",
       "      <td>0.593615</td>\n",
       "      <td>0.442607</td>\n",
       "      <td>0.260432</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.543276</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.461673</td>\n",
       "      <td>0.583330</td>\n",
       "      <td>0.729657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311223</td>\n",
       "      <td>0.473710</td>\n",
       "      <td>0.525864</td>\n",
       "      <td>0.478699</td>\n",
       "      <td>0.425248</td>\n",
       "      <td>0.556520</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.690165</td>\n",
       "      <td>0.601320</td>\n",
       "      <td>0.580802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.458787</td>\n",
       "      <td>0.481015</td>\n",
       "      <td>0.591830</td>\n",
       "      <td>0.585275</td>\n",
       "      <td>0.514705</td>\n",
       "      <td>0.434670</td>\n",
       "      <td>0.760067</td>\n",
       "      <td>0.478484</td>\n",
       "      <td>0.411925</td>\n",
       "      <td>0.571815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546258</td>\n",
       "      <td>0.444930</td>\n",
       "      <td>0.433473</td>\n",
       "      <td>0.493528</td>\n",
       "      <td>0.446758</td>\n",
       "      <td>0.454333</td>\n",
       "      <td>0.599957</td>\n",
       "      <td>0.417549</td>\n",
       "      <td>0.433475</td>\n",
       "      <td>0.549180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.567992</td>\n",
       "      <td>0.618241</td>\n",
       "      <td>0.716765</td>\n",
       "      <td>0.433966</td>\n",
       "      <td>0.502764</td>\n",
       "      <td>0.530721</td>\n",
       "      <td>0.737040</td>\n",
       "      <td>0.654448</td>\n",
       "      <td>0.448727</td>\n",
       "      <td>0.319203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497497</td>\n",
       "      <td>0.598123</td>\n",
       "      <td>0.423679</td>\n",
       "      <td>0.516171</td>\n",
       "      <td>0.520702</td>\n",
       "      <td>0.434551</td>\n",
       "      <td>0.535340</td>\n",
       "      <td>0.465929</td>\n",
       "      <td>0.673559</td>\n",
       "      <td>0.600705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.835591</td>\n",
       "      <td>0.716161</td>\n",
       "      <td>0.522494</td>\n",
       "      <td>0.764288</td>\n",
       "      <td>0.274877</td>\n",
       "      <td>0.642921</td>\n",
       "      <td>0.303752</td>\n",
       "      <td>0.648336</td>\n",
       "      <td>0.209125</td>\n",
       "      <td>0.313639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376443</td>\n",
       "      <td>0.442225</td>\n",
       "      <td>0.514548</td>\n",
       "      <td>0.634163</td>\n",
       "      <td>0.488613</td>\n",
       "      <td>0.578546</td>\n",
       "      <td>0.290164</td>\n",
       "      <td>0.457816</td>\n",
       "      <td>0.303048</td>\n",
       "      <td>0.385919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.453439  0.259504  0.460966  0.546587  0.528921  0.377153  0.524471   \n",
       "1  0.718723  0.593615  0.442607  0.260432  0.391372  0.543276  0.301724   \n",
       "2  0.458787  0.481015  0.591830  0.585275  0.514705  0.434670  0.760067   \n",
       "3  0.567992  0.618241  0.716765  0.433966  0.502764  0.530721  0.737040   \n",
       "4  0.835591  0.716161  0.522494  0.764288  0.274877  0.642921  0.303752   \n",
       "\n",
       "         7         8         9     ...           90        91        92  \\\n",
       "0  0.308691  0.629793  0.514874    ...     0.346300  0.540284  0.403092   \n",
       "1  0.461673  0.583330  0.729657    ...     0.311223  0.473710  0.525864   \n",
       "2  0.478484  0.411925  0.571815    ...     0.546258  0.444930  0.433473   \n",
       "3  0.654448  0.448727  0.319203    ...     0.497497  0.598123  0.423679   \n",
       "4  0.648336  0.209125  0.313639    ...     0.376443  0.442225  0.514548   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0  0.475057  0.391564  0.359514  0.533142  0.527310  0.418510  0.720473  \n",
       "1  0.478699  0.425248  0.556520  0.339448  0.690165  0.601320  0.580802  \n",
       "2  0.493528  0.446758  0.454333  0.599957  0.417549  0.433475  0.549180  \n",
       "3  0.516171  0.520702  0.434551  0.535340  0.465929  0.673559  0.600705  \n",
       "4  0.634163  0.488613  0.578546  0.290164  0.457816  0.303048  0.385919  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_X = DataFrame(pca_X)\n",
    "x = pca_X.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "pca_X = pandas.DataFrame(x_scaled)\n",
    "pca_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total label_1 of training set is 16162\n",
      "Total label_1 of test set is 3936\n"
     ]
    }
   ],
   "source": [
    "X_train3,X_test3, y_train3, y_test3 = train_test_split(pca_X, y, test_size=0.2)\n",
    "print('Total label_1 of training set is ' + str(sum(y_train3.target)))\n",
    "print('Total label_1 of test set is ' + str(sum(y_test3.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc = svm.SVC() \n",
    "svc.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_predict3=svc.predict(X_test3)\n",
    "print ('Original Data ROC AUC:%.3f'%roc_auc_score(y_true=y_test3,y_score=y_predict3))\n",
    "print ('Original Data Accuracy:%.3f'%accuracy_score(y_true=y_test3,y_pred=y_predict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**然后发现PCA降至50维也不行**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**？？？这个准确率？？表示完全都是猜的0，因为2000个test data，其中182个为1，其他的为0，如果都猜0的话，正确率正好是0.909，然后AUC正好是0.5，但是这是为什么？？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try K-NN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 13min 22s, sys: 21 s, total: 3h 13min 43s\n",
      "Wall time: 5h 23min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Let's iterate i in range(1,12), and find the i that can get the best(highest) accuracy on test data:\n",
    "i_and_accs = []\n",
    "for i in range(1,12):\n",
    "    k = i\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_test = knn.predict(X_test)\n",
    "    acc_test = knn.score(X_test, y_test)\n",
    "    y_pred_train = knn.predict(X_train)\n",
    "    acc_train = knn.score(X_train, y_train)\n",
    "    \n",
    "    i_and_accs.append([i,acc_test,acc_train])\n",
    "    \n",
    "i_and_accs #List of accuracies when i in range of 1 to 49, but haven't been sorted yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The k (whose range from 1 to 49) that can get the best accuracy is 3.\n",
      "The best accuracy on test data is 0.5473880597014925.\n",
      "CPU times: user 247 µs, sys: 270 µs, total: 517 µs\n",
      "Wall time: 277 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sorted_i_and_accs = sorted(i_and_accs, key=lambda x: x[1], reverse=True)\n",
    "best_k = sorted_i_and_accs[0][0]\n",
    "best_acc_test = sorted_i_and_accs[0][1]\n",
    "corresponding_acc_train = sorted_i_and_accs[0][2]\n",
    "print('The k (whose range from 1 to 49) that can get the best accuracy is '+str(best_k)+'.')\n",
    "print('The best accuracy on test data is '+str(best_acc_test)+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 0.5473880597014925, 0.7319940291080981],\n",
       " [5, 0.5432835820895522, 0.6639507401418087],\n",
       " [7, 0.5395522388059701, 0.6271613384749347],\n",
       " [1, 0.5370646766169154, 1.0],\n",
       " [9, 0.5370646766169154, 0.6037753451921881],\n",
       " [11, 0.5349502487562189, 0.5877285732056226],\n",
       " [6, 0.5205223880597015, 0.5874797860430402],\n",
       " [8, 0.5199004975124378, 0.5725525562880955],\n",
       " [4, 0.5190298507462686, 0.6093419579549695],\n",
       " [10, 0.5159203980099503, 0.5619169050876974],\n",
       " [2, 0.5140547263681592, 0.6488369200149272]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_i_and_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
